{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "malaria_DNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaluduggal/shaluduggal/blob/machinelearning/malaria_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0366e93"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Conv2D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "id": "a0366e93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a497aa1e",
        "outputId": "ee6a44b8-3d86-4092-a3ca-4d10dc1032cb"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "id": "a497aa1e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec27b811"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "train_path = 'cell_images/Train'\n",
        "valid_path = 'cell_images/Test'"
      ],
      "id": "ec27b811",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "831c220d"
      },
      "source": [
        "# add preprocessing layer to the front of VGG\n",
        "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n"
      ],
      "id": "831c220d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5c48632",
        "outputId": "eac91466-0ac2-476f-ab24-0215c336c8ce"
      },
      "source": [
        "vgg.summary()"
      ],
      "id": "d5c48632",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94289802",
        "outputId": "2fad6196-20f2-4da9-d5c8-41ce18b0224e"
      },
      "source": [
        "# useful for getting number of classes\n",
        "folders = glob('cell_images/*')\n",
        "folders"
      ],
      "id": "94289802",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cell_images\\\\Parasitized', 'cell_images\\\\Uninfected']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4abedf2"
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n"
      ],
      "id": "d4abedf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a21e0dd2",
        "outputId": "f170ef00-8a75-4ab9-c118-b3989da0530a"
      },
      "source": [
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "# view the structure of the model\n",
        "model.summary()\n"
      ],
      "id": "a21e0dd2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 20,074,562\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed5db3ed"
      },
      "source": [
        "# tell the model what cost and optimization method to use\n"
      ],
      "id": "ed5db3ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e838307a"
      },
      "source": [
        "#cnn model for the same : above is transfer learning\n",
        "#model=Sequential()\n",
        "#model.add(Conv2D(filters=16,kernel_size=2,padding='same',activation='relu',input_shape=[224,224]+[3]))\n",
        "#model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(500,activation='relu'))\n",
        "#model.add(Dense(2,activation='softmax'))\n",
        "#model.build()\n",
        "#model.summary()"
      ],
      "id": "e838307a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0f8bd44"
      },
      "source": [
        "\n",
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
        "           #image data augmentation zooming,shearing and scaling\n",
        "                                   \n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "id": "b0f8bd44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6f74c63",
        "outputId": "7a55d857-4361-414f-9952-a04bc31de14e"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('cell_images',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('cell_images',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n"
      ],
      "id": "c6f74c63",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27558 images belonging to 2 classes.\n",
            "Found 27558 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be5f8a47"
      },
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n"
      ],
      "id": "be5f8a47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ace5d32",
        "outputId": "0a293373-69a4-4785-ef68-6a564799e7c9"
      },
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=1,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")\n",
        "#epoch size=5"
      ],
      "id": "4ace5d32",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "767/862 [=========================>....] - ETA: 12:46 - loss: 0.3797 - accuracy: 0.8421"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f9ca282",
        "outputId": "1fcbe774-7774-4fcd-d493-4d0e34d691e3"
      },
      "source": [
        "# loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#plt.savefig('LossVal_loss')\n"
      ],
      "id": "2f9ca282",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea034e28",
        "outputId": "81b31f61-2d13-419a-dcd5-8d3d49963fcc"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='train acc')\n",
        "plt.plot(r.history['val_acc'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')\n",
        "\n"
      ],
      "id": "ea034e28",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'acc'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-42-ce1f3d107568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# accuracies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52545a21",
        "outputId": "862e5afb-1e97-414a-b518-f5d133a4d9fe"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('model_vgg19.h5')"
      ],
      "id": "52545a21",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-37-905ff55f2288>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-37-905ff55f2288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m r = model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2567\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2569\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2570\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    }
  ]
}